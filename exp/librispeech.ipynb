{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torchaudio\n",
    "import whisper\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1IMEkgyagYto"
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LibriSpeechEDA(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Modified version of LibriSpeech class to get raw audio lengths\n",
    "    \"\"\"\n",
    "    def __init__(self, split=\"test-clean\"):\n",
    "        self.dataset = torchaudio.datasets.LIBRISPEECH(\n",
    "            root=os.path.expanduser(\"~/.cache\"),\n",
    "            url=split,\n",
    "            download=True,\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        audio, sample_rate, text, _, _, _ = self.dataset[item]\n",
    "        return audio.shape[1] / sample_rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 2620\n",
      "Mean length: 7.42 seconds\n",
      "Median length: 5.79 seconds\n",
      "Min length: 1.28 seconds\n",
      "Max length: 34.95 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_eda = LibriSpeechEDA(\"test-clean\")\n",
    "lengths = [dataset_eda[i] for i in range(len(dataset_eda))]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(lengths, bins=50)\n",
    "plt.title('Audio Length Distribution in LibriSpeech test-clean')\n",
    "plt.xlabel('Duration (seconds)')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "print(f\"Total samples: {len(lengths)}\")\n",
    "print(f\"Mean length: {np.mean(lengths):.2f} seconds\")\n",
    "print(f\"Median length: {np.median(lengths):.2f} seconds\")\n",
    "print(f\"Min length: {np.min(lengths):.2f} seconds\")\n",
    "print(f\"Max length: {np.max(lengths):.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ljocCNuUAde"
   },
   "source": [
    "# Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LibriSpeechWhisper(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    A simple class to wrap LibriSpeech and trim/pad the audio to 30 seconds.\n",
    "    It will drop the last few seconds of a very small portion of the utterances.\n",
    "    \"\"\"\n",
    "    def __init__(self, split=\"test-clean\"):\n",
    "        self.dataset = torchaudio.datasets.LIBRISPEECH(\n",
    "            root=os.path.expanduser(\"~/.cache\"),\n",
    "            url=split,\n",
    "            download=True,\n",
    "        )\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        audio, sample_rate, text, _, _, _ = self.dataset[item]\n",
    "        assert sample_rate == 16000\n",
    "        audio = whisper.pad_or_trim(audio.flatten()).to(self.device)\n",
    "        mel = whisper.log_mel_spectrogram(audio)\n",
    "        return (mel, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LibriSpeechWhisper(\"test-other\")\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_PokfNJtOYNu",
    "outputId": "2c53ec44-bc93-4107-b4fa-214e3f71fe8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is multilingual and has 762,321,920 parameters.\n"
     ]
    }
   ],
   "source": [
    "model = whisper.load_model(\"medium\")\n",
    "print(\n",
    "    f\"Model is {'multilingual' if model.is_multilingual else 'English-only'} \"\n",
    "    f\"and has {sum(np.prod(p.shape) for p in model.parameters()):,} parameters.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict without timestamps for short-form transcription\n",
    "options = whisper.DecodingOptions(language=\"en\", without_timestamps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "09a29a91f58d4462942505a3cc415801",
      "83391f98a240490987c397048fc1a0d4",
      "06b9aa5f49fa44ba8c93b647dc7db224",
      "da9c231ee67047fb89073c95326b72a5",
      "48da931ebe7f4fd299f8c98c7d2460ff",
      "7a901f447c1d477bb49f954e0feacedd",
      "39f5a6ae8ba74c8598f9c6d5b8ad2d65",
      "a0d10a42c753453283e5219c22239337",
      "09f4cb79ff86465aaf48b0de24869af9",
      "1b9cecf5b3584fba8258a81d4279a25b",
      "039b53f2702c4179af7e0548018d0588"
     ]
    },
    "id": "7OWTn_KvNk59",
    "outputId": "a813a792-3c91-4144-f11f-054fd6778023"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b3e478c3eeb4ee78df1e6553edc42f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = []\n",
    "gt = []\n",
    "\n",
    "for mels, texts in tqdm(loader):\n",
    "    results = model.decode(mels, options)\n",
    "    predictions.extend([result.text for result in results])\n",
    "    gt.extend(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "4nTyynELQ42j",
    "outputId": "1c72d25a-3e87-4c60-a8d1-1da9d2f73bd7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "      <th>gt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There's iron, they say, in all our blood, And ...</td>\n",
       "      <td>THERE'S IRON THEY SAY IN ALL OUR BLOOD AND A G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"'Margaret,' said Mr. Hale, as he returned fro...</td>\n",
       "      <td>MARGARET SAID MISTER HALE AS HE RETURNED FROM ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You don't mean that you thought me so silly.</td>\n",
       "      <td>YOU DON'T MEAN THAT YOU THOUGHT ME SO SILLY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I really liked that account of himself. Better...</td>\n",
       "      <td>I REALLY LIKED THAT ACCOUNT OF HIMSELF BETTER ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>His statement of having been a shop boy was th...</td>\n",
       "      <td>HIS STATEMENT OF HAVING BEEN A SHOP BOY WAS TH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2934</th>\n",
       "      <td>Poor Isaac was hurried off accordingly, and ex...</td>\n",
       "      <td>POOR ISAAC WAS HURRIED OFF ACCORDINGLY AND EXP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935</th>\n",
       "      <td>The assurance that she possessed some friend i...</td>\n",
       "      <td>THE ASSURANCE THAT SHE POSSESSED SOME FRIEND I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2936</th>\n",
       "      <td>She gazed accordingly upon a scene which might...</td>\n",
       "      <td>SHE GAZED ACCORDINGLY UPON A SCENE WHICH MIGHT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2937</th>\n",
       "      <td>At his feet was placed a table, occupied by tw...</td>\n",
       "      <td>AT HIS FEET WAS PLACED A TABLE OCCUPIED BY TWO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2938</th>\n",
       "      <td>The preceptors, of whom there were four presen...</td>\n",
       "      <td>THE PRECEPTORS OF WHOM THERE WERE FOUR PRESENT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2939 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            predictions  \\\n",
       "0     There's iron, they say, in all our blood, And ...   \n",
       "1     \"'Margaret,' said Mr. Hale, as he returned fro...   \n",
       "2          You don't mean that you thought me so silly.   \n",
       "3     I really liked that account of himself. Better...   \n",
       "4     His statement of having been a shop boy was th...   \n",
       "...                                                 ...   \n",
       "2934  Poor Isaac was hurried off accordingly, and ex...   \n",
       "2935  The assurance that she possessed some friend i...   \n",
       "2936  She gazed accordingly upon a scene which might...   \n",
       "2937  At his feet was placed a table, occupied by tw...   \n",
       "2938  The preceptors, of whom there were four presen...   \n",
       "\n",
       "                                                     gt  \n",
       "0     THERE'S IRON THEY SAY IN ALL OUR BLOOD AND A G...  \n",
       "1     MARGARET SAID MISTER HALE AS HE RETURNED FROM ...  \n",
       "2           YOU DON'T MEAN THAT YOU THOUGHT ME SO SILLY  \n",
       "3     I REALLY LIKED THAT ACCOUNT OF HIMSELF BETTER ...  \n",
       "4     HIS STATEMENT OF HAVING BEEN A SHOP BOY WAS TH...  \n",
       "...                                                 ...  \n",
       "2934  POOR ISAAC WAS HURRIED OFF ACCORDINGLY AND EXP...  \n",
       "2935  THE ASSURANCE THAT SHE POSSESSED SOME FRIEND I...  \n",
       "2936  SHE GAZED ACCORDINGLY UPON A SCENE WHICH MIGHT...  \n",
       "2937  AT HIS FEET WAS PLACED A TABLE OCCUPIED BY TWO...  \n",
       "2938  THE PRECEPTORS OF WHOM THERE WERE FOUR PRESENT...  \n",
       "\n",
       "[2939 rows x 2 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(dict(predictions=predictions, gt=gt))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "dl-KBDflMhrg"
   },
   "outputs": [],
   "source": [
    "# WER\n",
    "import jiwer\n",
    "from whisper.normalizers import EnglishTextNormalizer\n",
    "\n",
    "normalizer = EnglishTextNormalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "id": "6-O048q4WI4o",
    "outputId": "f2089bc9-f535-441e-f192-26e52ae82b5e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "      <th>gt</th>\n",
       "      <th>predictions_clean</th>\n",
       "      <th>gt_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There's iron, they say, in all our blood, And ...</td>\n",
       "      <td>THERE'S IRON THEY SAY IN ALL OUR BLOOD AND A G...</td>\n",
       "      <td>there is iron they say in all our blood and a ...</td>\n",
       "      <td>there is iron they say in all our blood and a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"'Margaret,' said Mr. Hale, as he returned fro...</td>\n",
       "      <td>MARGARET SAID MISTER HALE AS HE RETURNED FROM ...</td>\n",
       "      <td>margaret said mister hale as he returned from ...</td>\n",
       "      <td>margaret said mister hale as he returned from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You don't mean that you thought me so silly.</td>\n",
       "      <td>YOU DON'T MEAN THAT YOU THOUGHT ME SO SILLY</td>\n",
       "      <td>you do not mean that you thought me so silly</td>\n",
       "      <td>you do not mean that you thought me so silly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I really liked that account of himself. Better...</td>\n",
       "      <td>I REALLY LIKED THAT ACCOUNT OF HIMSELF BETTER ...</td>\n",
       "      <td>i really liked that account of himself better ...</td>\n",
       "      <td>i really liked that account of himself better ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>His statement of having been a shop boy was th...</td>\n",
       "      <td>HIS STATEMENT OF HAVING BEEN A SHOP BOY WAS TH...</td>\n",
       "      <td>his statement of having been a shop boy was th...</td>\n",
       "      <td>his statement of having been a shop boy was th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2934</th>\n",
       "      <td>Poor Isaac was hurried off accordingly, and ex...</td>\n",
       "      <td>POOR ISAAC WAS HURRIED OFF ACCORDINGLY AND EXP...</td>\n",
       "      <td>poor isaac was hurried off accordingly and exp...</td>\n",
       "      <td>poor isaac was hurried off accordingly and exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935</th>\n",
       "      <td>The assurance that she possessed some friend i...</td>\n",
       "      <td>THE ASSURANCE THAT SHE POSSESSED SOME FRIEND I...</td>\n",
       "      <td>the assurance that she possessed some friend i...</td>\n",
       "      <td>the assurance that she possessed some friend i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2936</th>\n",
       "      <td>She gazed accordingly upon a scene which might...</td>\n",
       "      <td>SHE GAZED ACCORDINGLY UPON A SCENE WHICH MIGHT...</td>\n",
       "      <td>she gazed accordingly upon a scene which might...</td>\n",
       "      <td>she gazed accordingly upon a scene which might...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2937</th>\n",
       "      <td>At his feet was placed a table, occupied by tw...</td>\n",
       "      <td>AT HIS FEET WAS PLACED A TABLE OCCUPIED BY TWO...</td>\n",
       "      <td>at his feet was placed a table occupied by 2 s...</td>\n",
       "      <td>at his feet was placed a table occupied by 2 s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2938</th>\n",
       "      <td>The preceptors, of whom there were four presen...</td>\n",
       "      <td>THE PRECEPTORS OF WHOM THERE WERE FOUR PRESENT...</td>\n",
       "      <td>the preceptors of whom there were 4 present oc...</td>\n",
       "      <td>the preceptors of whom there were 4 present oc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2939 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            predictions  \\\n",
       "0     There's iron, they say, in all our blood, And ...   \n",
       "1     \"'Margaret,' said Mr. Hale, as he returned fro...   \n",
       "2          You don't mean that you thought me so silly.   \n",
       "3     I really liked that account of himself. Better...   \n",
       "4     His statement of having been a shop boy was th...   \n",
       "...                                                 ...   \n",
       "2934  Poor Isaac was hurried off accordingly, and ex...   \n",
       "2935  The assurance that she possessed some friend i...   \n",
       "2936  She gazed accordingly upon a scene which might...   \n",
       "2937  At his feet was placed a table, occupied by tw...   \n",
       "2938  The preceptors, of whom there were four presen...   \n",
       "\n",
       "                                                     gt  \\\n",
       "0     THERE'S IRON THEY SAY IN ALL OUR BLOOD AND A G...   \n",
       "1     MARGARET SAID MISTER HALE AS HE RETURNED FROM ...   \n",
       "2           YOU DON'T MEAN THAT YOU THOUGHT ME SO SILLY   \n",
       "3     I REALLY LIKED THAT ACCOUNT OF HIMSELF BETTER ...   \n",
       "4     HIS STATEMENT OF HAVING BEEN A SHOP BOY WAS TH...   \n",
       "...                                                 ...   \n",
       "2934  POOR ISAAC WAS HURRIED OFF ACCORDINGLY AND EXP...   \n",
       "2935  THE ASSURANCE THAT SHE POSSESSED SOME FRIEND I...   \n",
       "2936  SHE GAZED ACCORDINGLY UPON A SCENE WHICH MIGHT...   \n",
       "2937  AT HIS FEET WAS PLACED A TABLE OCCUPIED BY TWO...   \n",
       "2938  THE PRECEPTORS OF WHOM THERE WERE FOUR PRESENT...   \n",
       "\n",
       "                                      predictions_clean  \\\n",
       "0     there is iron they say in all our blood and a ...   \n",
       "1     margaret said mister hale as he returned from ...   \n",
       "2          you do not mean that you thought me so silly   \n",
       "3     i really liked that account of himself better ...   \n",
       "4     his statement of having been a shop boy was th...   \n",
       "...                                                 ...   \n",
       "2934  poor isaac was hurried off accordingly and exp...   \n",
       "2935  the assurance that she possessed some friend i...   \n",
       "2936  she gazed accordingly upon a scene which might...   \n",
       "2937  at his feet was placed a table occupied by 2 s...   \n",
       "2938  the preceptors of whom there were 4 present oc...   \n",
       "\n",
       "                                               gt_clean  \n",
       "0     there is iron they say in all our blood and a ...  \n",
       "1     margaret said mister hale as he returned from ...  \n",
       "2          you do not mean that you thought me so silly  \n",
       "3     i really liked that account of himself better ...  \n",
       "4     his statement of having been a shop boy was th...  \n",
       "...                                                 ...  \n",
       "2934  poor isaac was hurried off accordingly and exp...  \n",
       "2935  the assurance that she possessed some friend i...  \n",
       "2936  she gazed accordingly upon a scene which might...  \n",
       "2937  at his feet was placed a table occupied by 2 s...  \n",
       "2938  the preceptors of whom there were 4 present oc...  \n",
       "\n",
       "[2939 rows x 4 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"predictions_clean\"] = [normalizer(text) for text in data[\"predictions\"]]\n",
    "data[\"gt_clean\"] = [normalizer(text) for text in data[\"gt\"]]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EBGSITeBYPTT",
    "outputId": "7b3dbe7c-a37e-4a07-a50a-b27d5f88b68f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER: 6.04 %\n"
     ]
    }
   ],
   "source": [
    "wer = jiwer.wer(list(data[\"gt_clean\"]), list(data[\"predictions_clean\"]))\n",
    "\n",
    "print(f\"WER: {wer * 100:.2f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ichigo-ASR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LibriSpeechIchigo(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    A simple class to wrap LibriSpeech and trim/pad the audio to 30 seconds.\n",
    "    It will drop the last few seconds of a very small portion of the utterances.\n",
    "    \"\"\"\n",
    "    def __init__(self, split=\"test-clean\"):\n",
    "        self.dataset = torchaudio.datasets.LIBRISPEECH(\n",
    "            root=os.path.expanduser(\"~/.cache\"),\n",
    "            url=split,\n",
    "            download=True,\n",
    "        )\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        audio, sample_rate, text, _, _, _ = self.dataset[item]\n",
    "        audio = audio.to(self.device)\n",
    "        assert sample_rate == 16000\n",
    "        return (audio, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2620\n"
     ]
    }
   ],
   "source": [
    "dataset = LibriSpeechIchigo(\"test-clean\")\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ichigo.asr import IchigoASR\n",
    "asr = IchigoASR(config=\"merge-2560d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "417c0bd015014dd7b25db980934acee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2620 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He hoped there would be stew for dinner, turnips and carrots and bruised potatoes, and fat mutton pieces to be ladled out in thick peppered flour fattened sauce.\n",
      "'Stuff it into you.' His belly countered him.\n",
      "After early nightfall the yellow lamps would light up, here and there, the squalid quarter of the brothels.\n",
      "Hello, Bertie, any good in your mind?\n",
      "Number ten, Fresh Nellie is waiting on you. Good night, husband.\n",
      "The music came nearer and he recalled the words, the words of Shelley's fragment upon the moon wandering companionless, pale for weariness.\n",
      "The dull light fell more faintly upon the page, whereon another equation began to unfold itself slowly and to spread abroad its widening tail.\n",
      "A cold, lucid indifference reigned in his soul.\n",
      "The chaos in which his ardour extinguished itself was a cold, indifferent knowledge of himself.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mid\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dataset))):\n\u001b[1;32m      5\u001b[0m     audio, texts \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;28mid\u001b[39m]\n\u001b[0;32m----> 6\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43masr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranscribe_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_sec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverlap_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mappend(results)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(results)\n",
      "File \u001b[0;32m/opt/conda/envs/ichigo-inference/lib/python3.11/site-packages/ichigo/asr/transcriber.py:276\u001b[0m, in \u001b[0;36mIchigoASR.transcribe_tensor\u001b[0;34m(self, wav, chunk_sec, overlap_size)\u001b[0m\n\u001b[1;32m    274\u001b[0m     embs, n_frames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ms2r(chunk)\n\u001b[1;32m    275\u001b[0m     dequantize_embed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquantizer(embs, n_frames)\n\u001b[0;32m--> 276\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mr2t\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdequantize_embed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(result[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip())\n\u001b[1;32m    278\u001b[0m transcript \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(results)\n",
      "File \u001b[0;32m/opt/conda/envs/ichigo-inference/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/ichigo-inference/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/envs/ichigo-inference/lib/python3.11/site-packages/ichigo/asr/arch/r2t.py:19\u001b[0m, in \u001b[0;36mRep2Text.forward\u001b[0;34m(self, dequantize_embed)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, dequantize_embed):\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdequantize_embed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoding_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/ichigo-inference/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/ichigo-inference/lib/python3.11/site-packages/whisper/decoding.py:824\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(model, mel, options, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m    822\u001b[0m     options \u001b[38;5;241m=\u001b[39m replace(options, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 824\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mDecodingTask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m single \u001b[38;5;28;01melse\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/envs/ichigo-inference/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/ichigo-inference/lib/python3.11/site-packages/whisper/decoding.py:737\u001b[0m, in \u001b[0;36mDecodingTask.run\u001b[0;34m(self, mel)\u001b[0m\n\u001b[1;32m    734\u001b[0m tokens \u001b[38;5;241m=\u001b[39m tokens\u001b[38;5;241m.\u001b[39mrepeat_interleave(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_group, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(audio_features\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    736\u001b[0m \u001b[38;5;66;03m# call the main sampling loop\u001b[39;00m\n\u001b[0;32m--> 737\u001b[0m tokens, sum_logprobs, no_speech_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_main_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;66;03m# reshape the tensors to have (n_audio, n_group) as the first two dimensions\u001b[39;00m\n\u001b[1;32m    740\u001b[0m audio_features \u001b[38;5;241m=\u001b[39m audio_features[:: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_group]\n",
      "File \u001b[0;32m/opt/conda/envs/ichigo-inference/lib/python3.11/site-packages/whisper/decoding.py:687\u001b[0m, in \u001b[0;36mDecodingTask._main_loop\u001b[0;34m(self, audio_features, tokens)\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_len):\n\u001b[0;32m--> 687\u001b[0m         logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    689\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    690\u001b[0m             i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mno_speech \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    691\u001b[0m         ):  \u001b[38;5;66;03m# save no_speech_probs\u001b[39;00m\n\u001b[1;32m    692\u001b[0m             probs_at_sot \u001b[38;5;241m=\u001b[39m logits[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msot_index]\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39msoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/ichigo-inference/lib/python3.11/site-packages/whisper/decoding.py:163\u001b[0m, in \u001b[0;36mPyTorchInference.logits\u001b[0;34m(self, tokens, audio_features)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokens\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_token_length:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# only need to use the last token except in the first forward pass\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m tokens[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkv_cache\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/ichigo-inference/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/ichigo-inference/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/envs/ichigo-inference/lib/python3.11/site-packages/whisper/model.py:242\u001b[0m, in \u001b[0;36mTextDecoder.forward\u001b[0;34m(self, x, xa, kv_cache)\u001b[0m\n\u001b[1;32m    239\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(xa\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m--> 242\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkv_cache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln(x)\n\u001b[1;32m    245\u001b[0m logits \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    246\u001b[0m     x \u001b[38;5;241m@\u001b[39m torch\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_embedding\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdtype), \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    247\u001b[0m )\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[0;32m/opt/conda/envs/ichigo-inference/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/ichigo-inference/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/envs/ichigo-inference/lib/python3.11/site-packages/whisper/model.py:167\u001b[0m, in \u001b[0;36mResidualAttentionBlock.forward\u001b[0;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    162\u001b[0m     x: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    165\u001b[0m     kv_cache: Optional[\u001b[38;5;28mdict\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    166\u001b[0m ):\n\u001b[0;32m--> 167\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn_ln\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkv_cache\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attn:\n\u001b[1;32m    169\u001b[0m         x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attn_ln(x), xa, kv_cache\u001b[38;5;241m=\u001b[39mkv_cache)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/envs/ichigo-inference/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/ichigo-inference/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/envs/ichigo-inference/lib/python3.11/site-packages/whisper/model.py:111\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[0;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[1;32m    108\u001b[0m     k \u001b[38;5;241m=\u001b[39m kv_cache[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey]\n\u001b[1;32m    109\u001b[0m     v \u001b[38;5;241m=\u001b[39m kv_cache[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue]\n\u001b[0;32m--> 111\u001b[0m wv, qk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqkv_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout(wv), qk\n",
      "File \u001b[0;32m/opt/conda/envs/ichigo-inference/lib/python3.11/site-packages/whisper/model.py:119\u001b[0m, in \u001b[0;36mMultiHeadAttention.qkv_attention\u001b[0;34m(self, q, k, v, mask)\u001b[0m\n\u001b[1;32m    117\u001b[0m n_batch, n_ctx, n_state \u001b[38;5;241m=\u001b[39m q\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    118\u001b[0m scale \u001b[38;5;241m=\u001b[39m (n_state \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_head) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[0;32m--> 119\u001b[0m q \u001b[38;5;241m=\u001b[39m \u001b[43mq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_head\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m k \u001b[38;5;241m=\u001b[39m k\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m*\u001b[39mk\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_head, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m    121\u001b[0m v \u001b[38;5;241m=\u001b[39m v\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m*\u001b[39mv\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_head, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "gt = []\n",
    "\n",
    "for id in tqdm(range(len(dataset))):\n",
    "    audio, texts = dataset[id]\n",
    "    results = asr.transcribe_tensor(audio, chunk_sec=20, overlap_size=1)\n",
    "    predictions.append(results)\n",
    "    gt.append(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jiwer\n",
    "from whisper.normalizers import EnglishTextNormalizer\n",
    "\n",
    "data = pd.DataFrame(dict(predictions=predictions, gt=gt))\n",
    "data.to_csv('ichigo_c20_o1.csv')\n",
    "\n",
    "normalizer = EnglishTextNormalizer()\n",
    "\n",
    "data[\"predictions_clean\"] = [normalizer(text) for text in data[\"predictions\"]]\n",
    "data[\"gt_clean\"] = [normalizer(text) for text in data[\"gt\"]]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>predictions</th>\n",
       "      <th>gt</th>\n",
       "      <th>predictions_clean</th>\n",
       "      <th>gt_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.435000</td>\n",
       "      <td>'He hoped there would be stew for dinner, turn...</td>\n",
       "      <td>HE HOPED THERE WOULD BE STEW FOR DINNER TURNIP...</td>\n",
       "      <td>he hoped there would be stew for dinner turnip...</td>\n",
       "      <td>he hoped there would be stew for dinner turnip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.275000</td>\n",
       "      <td>'Stuff it into you.' His belly countered him.</td>\n",
       "      <td>STUFF IT INTO YOU HIS BELLY COUNSELLED HIM</td>\n",
       "      <td>stuff it into you his belly countered him</td>\n",
       "      <td>stuff it into you his belly counseled him</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.625000</td>\n",
       "      <td>After early nightfall the yellow lamps would l...</td>\n",
       "      <td>AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD L...</td>\n",
       "      <td>after early nightfall the yellow lamps would l...</td>\n",
       "      <td>after early nightfall the yellow lamps would l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.680000</td>\n",
       "      <td>Hello, Bertie, any good in your mind?</td>\n",
       "      <td>HELLO BERTIE ANY GOOD IN YOUR MIND</td>\n",
       "      <td>hello bertie any good in your mind</td>\n",
       "      <td>hello bertie any good in your mind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.215063</td>\n",
       "      <td>'Number ten, fresh Nellie is waiting on you. G...</td>\n",
       "      <td>NUMBER TEN FRESH NELLY IS WAITING ON YOU GOOD ...</td>\n",
       "      <td>number 10 fresh nellie is waiting on you good ...</td>\n",
       "      <td>number 10 fresh nelly is waiting on you good n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2615</th>\n",
       "      <td>10.905000</td>\n",
       "      <td>Oh! to shoot my soul's full meaning into futur...</td>\n",
       "      <td>OH TO SHOOT MY SOUL'S FULL MEANING INTO FUTURE...</td>\n",
       "      <td>0 to shoot my soul is full meaning into future...</td>\n",
       "      <td>0 to shoot my soul is full meaning into future...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2616</th>\n",
       "      <td>14.100000</td>\n",
       "      <td>Then I, long tried by natural ills, received t...</td>\n",
       "      <td>THEN I LONG TRIED BY NATURAL ILLS RECEIVED THE...</td>\n",
       "      <td>then i long tried by natural ills received the...</td>\n",
       "      <td>then i long tried by natural ills received the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2617</th>\n",
       "      <td>8.515000</td>\n",
       "      <td>I love thee freely, as men strive for right. I...</td>\n",
       "      <td>I LOVE THEE FREELY AS MEN STRIVE FOR RIGHT I L...</td>\n",
       "      <td>i love thee freely as men strive for right i l...</td>\n",
       "      <td>i love thee freely as men strive for right i l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2618</th>\n",
       "      <td>7.540000</td>\n",
       "      <td>I love thee with the passion put to use in my ...</td>\n",
       "      <td>I LOVE THEE WITH THE PASSION PUT TO USE IN MY ...</td>\n",
       "      <td>i love thee with the passion put to use in my ...</td>\n",
       "      <td>i love thee with the passion put to use in my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2619</th>\n",
       "      <td>20.560000</td>\n",
       "      <td>'I love thee with a love I seemed to lose with...</td>\n",
       "      <td>I LOVE THEE WITH A LOVE I SEEMED TO LOSE WITH ...</td>\n",
       "      <td>i love thee with a love i seemed to lose with ...</td>\n",
       "      <td>i love thee with a love i seemed to lose with ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2620 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       duration                                        predictions  \\\n",
       "0     10.435000  'He hoped there would be stew for dinner, turn...   \n",
       "1      3.275000      'Stuff it into you.' His belly countered him.   \n",
       "2      6.625000  After early nightfall the yellow lamps would l...   \n",
       "3      2.680000              Hello, Bertie, any good in your mind?   \n",
       "4      5.215063  'Number ten, fresh Nellie is waiting on you. G...   \n",
       "...         ...                                                ...   \n",
       "2615  10.905000  Oh! to shoot my soul's full meaning into futur...   \n",
       "2616  14.100000  Then I, long tried by natural ills, received t...   \n",
       "2617   8.515000  I love thee freely, as men strive for right. I...   \n",
       "2618   7.540000  I love thee with the passion put to use in my ...   \n",
       "2619  20.560000  'I love thee with a love I seemed to lose with...   \n",
       "\n",
       "                                                     gt  \\\n",
       "0     HE HOPED THERE WOULD BE STEW FOR DINNER TURNIP...   \n",
       "1            STUFF IT INTO YOU HIS BELLY COUNSELLED HIM   \n",
       "2     AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD L...   \n",
       "3                    HELLO BERTIE ANY GOOD IN YOUR MIND   \n",
       "4     NUMBER TEN FRESH NELLY IS WAITING ON YOU GOOD ...   \n",
       "...                                                 ...   \n",
       "2615  OH TO SHOOT MY SOUL'S FULL MEANING INTO FUTURE...   \n",
       "2616  THEN I LONG TRIED BY NATURAL ILLS RECEIVED THE...   \n",
       "2617  I LOVE THEE FREELY AS MEN STRIVE FOR RIGHT I L...   \n",
       "2618  I LOVE THEE WITH THE PASSION PUT TO USE IN MY ...   \n",
       "2619  I LOVE THEE WITH A LOVE I SEEMED TO LOSE WITH ...   \n",
       "\n",
       "                                      predictions_clean  \\\n",
       "0     he hoped there would be stew for dinner turnip...   \n",
       "1             stuff it into you his belly countered him   \n",
       "2     after early nightfall the yellow lamps would l...   \n",
       "3                    hello bertie any good in your mind   \n",
       "4     number 10 fresh nellie is waiting on you good ...   \n",
       "...                                                 ...   \n",
       "2615  0 to shoot my soul is full meaning into future...   \n",
       "2616  then i long tried by natural ills received the...   \n",
       "2617  i love thee freely as men strive for right i l...   \n",
       "2618  i love thee with the passion put to use in my ...   \n",
       "2619  i love thee with a love i seemed to lose with ...   \n",
       "\n",
       "                                               gt_clean  \n",
       "0     he hoped there would be stew for dinner turnip...  \n",
       "1             stuff it into you his belly counseled him  \n",
       "2     after early nightfall the yellow lamps would l...  \n",
       "3                    hello bertie any good in your mind  \n",
       "4     number 10 fresh nelly is waiting on you good n...  \n",
       "...                                                 ...  \n",
       "2615  0 to shoot my soul is full meaning into future...  \n",
       "2616  then i long tried by natural ills received the...  \n",
       "2617  i love thee freely as men strive for right i l...  \n",
       "2618  i love thee with the passion put to use in my ...  \n",
       "2619  i love thee with a love i seemed to lose with ...  \n",
       "\n",
       "[2620 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 614 entries, 0 to 2619\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   duration           614 non-null    float64\n",
      " 1   predictions        614 non-null    object \n",
      " 2   gt                 614 non-null    object \n",
      " 3   predictions_clean  614 non-null    object \n",
      " 4   gt_clean           614 non-null    object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 28.8+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import jiwer\n",
    "\n",
    "data = pd.read_csv('/root/ichigo/librispeech/ichigo_resultstest-clean/chunk5_overlap0.5.csv')\n",
    "data = data[data[\"duration\"] >= 10]\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 614 entries, 0 to 2619\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   duration           614 non-null    float64\n",
      " 1   predictions        614 non-null    object \n",
      " 2   gt                 614 non-null    object \n",
      " 3   predictions_clean  614 non-null    object \n",
      " 4   gt_clean           614 non-null    object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 28.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data = data.dropna()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER: 14.95 %\n"
     ]
    }
   ],
   "source": [
    "wer = jiwer.wer(list(data[\"gt_clean\"]), list(data[\"predictions_clean\"]))\n",
    "\n",
    "print(f\"WER: {wer * 100:.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "ichigo-inference",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "039b53f2702c4179af7e0548018d0588": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "06b9aa5f49fa44ba8c93b647dc7db224": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0d10a42c753453283e5219c22239337",
      "max": 164,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_09f4cb79ff86465aaf48b0de24869af9",
      "value": 164
     }
    },
    "09a29a91f58d4462942505a3cc415801": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_83391f98a240490987c397048fc1a0d4",
       "IPY_MODEL_06b9aa5f49fa44ba8c93b647dc7db224",
       "IPY_MODEL_da9c231ee67047fb89073c95326b72a5"
      ],
      "layout": "IPY_MODEL_48da931ebe7f4fd299f8c98c7d2460ff"
     }
    },
    "09f4cb79ff86465aaf48b0de24869af9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1b9cecf5b3584fba8258a81d4279a25b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39f5a6ae8ba74c8598f9c6d5b8ad2d65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "48da931ebe7f4fd299f8c98c7d2460ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a901f447c1d477bb49f954e0feacedd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "83391f98a240490987c397048fc1a0d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a901f447c1d477bb49f954e0feacedd",
      "placeholder": "​",
      "style": "IPY_MODEL_39f5a6ae8ba74c8598f9c6d5b8ad2d65",
      "value": "100%"
     }
    },
    "a0d10a42c753453283e5219c22239337": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "da9c231ee67047fb89073c95326b72a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b9cecf5b3584fba8258a81d4279a25b",
      "placeholder": "​",
      "style": "IPY_MODEL_039b53f2702c4179af7e0548018d0588",
      "value": " 164/164 [05:08&lt;00:00,  1.86s/it]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
